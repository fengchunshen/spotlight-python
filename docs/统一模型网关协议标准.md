### 1. 核心架构定位
本平台采用 **OneAPI** 作为底层的**中间件**，结合 **RuoYi-Cloud** 的**策略控制层**，构建双层模型网关架构。

+ **差异屏蔽**：无论底层是 DeepSeek、Qwen、OpenAI 还是 Azure，对外统一暴露标准的 **OpenAI API 接口规范**。Python 执行平面无需适配不同厂商的 SDK，仅需维护一套 OpenAI Client 代码。
+ **存算分离**：
    - **OneAPI** 负责“连接”：管理渠道（Channel）、负载均衡、重试机制。
    - **RuoYi** 负责“定义”：管理定价、权限、上下文窗口、上架状态。



### 2. 管理平面规范 (RuoYi-Cloud)
RuoYi 侧不存储具体的 API Key（这些托管在 OneAPI 中），而是专注于**商业化定义**与**模型元数据管理**。

#### 2.1 模型注册表 (`sys_ai_model`)
该表定义了平台对外的模型服务能力，是前端“模型选择器”的数据源。

| **<font style="color:rgb(31, 31, 31);">字段名</font>** | **<font style="color:rgb(31, 31, 31);">关键说明</font>** | **<font style="color:rgb(31, 31, 31);">业务逻辑作用</font>** |
| --- | --- | --- |
| `<font style="color:rgb(68, 71, 70);">model_code</font>` | <font style="color:rgb(31, 31, 31);">调用标识</font> | **<font style="color:rgb(31, 31, 31);">核心映射键</font>**<font style="color:rgb(31, 31, 31);">：必须与 OneAPI 中创建的“渠道模型名称”或“重定向名称”严格一致（如 </font>`<font style="color:rgb(68, 71, 70);">deepseek-chat</font>`<br/><font style="color:rgb(31, 31, 31);">）。</font> |
| `<font style="color:rgb(68, 71, 70);">context_window</font>` | <font style="color:rgb(31, 31, 31);">上下文窗口</font> | **<font style="color:rgb(31, 31, 31);">溢出保护</font>**<font style="color:rgb(31, 31, 31);">：RuoYi 在组装 Payload 前，会计算历史消息 Token。若超过此值，触发“记忆压缩”策略。</font> |
| `<font style="color:rgb(68, 71, 70);">price_input</font>` | <font style="color:rgb(31, 31, 31);">提示价格</font> | **<font style="color:rgb(31, 31, 31);">计费基准</font>**<font style="color:rgb(31, 31, 31);">：单位（元/1k tokens）。用于计算用户输入的成本。</font> |
| `<font style="color:rgb(68, 71, 70);">price_output</font>` | <font style="color:rgb(31, 31, 31);">补全价格</font> | **<font style="color:rgb(31, 31, 31);">计费基准</font>**<font style="color:rgb(31, 31, 31);">：单位（元/1k tokens）。用于计算模型输出的成本。</font> |
| `<font style="color:rgb(68, 71, 70);">provider</font>` | <font style="color:rgb(31, 31, 31);">厂商标识</font> | <font style="color:rgb(31, 31, 31);">用于前端渲染厂商图标（如 </font>`<font style="color:rgb(68, 71, 70);">icon-deepseek</font>`<br/><font style="color:rgb(31, 31, 31);">）。</font> |


#### 2.2 渠道映射策略
RuoYi 不直接管理厂商 Key，而是管理 **OneAPI 访问令牌**。

+ **配置方式**：在 RuoYi 系统参数中配置全局唯一的 `ONEAPI_BASE_URL` 和 `ONEAPI_MASTER_KEY`。
+ **动态令牌**：或者，RuoYi 可为不同等级的用户（如 VIP/普通）生成不同的 OneAPI 令牌，以实现基于 OneAPI 的流控。

### 3. 运行时注入协议
在用户发起对话时，RuoYi 负责将静态的模型定义转化为动态的**运行时配置 (**`**model_config**`**)**。

 

#### 3.1 载荷组装
RuoYi 根据用户前端选择的 `model_id`，查询 `sys_ai_model`，并将以下信息注入 Payload 发送给 Python：

```java
{
  // ... 其他字段 ...
  "model_config": {
    "provider": "openai", // 固定为 openai，因 OneAPI 实现了接口统一
    "model_name": "deepseek-chat", // 对应 sys_ai_model.model_code
    "base_url": "http://one-api-service:3000/v1", // 指向内部 OneAPI 地址
    "api_key": "sk-oneapi-token-...", // OneAPI 的聚合 Token
    "temperature": 0.7,
    "max_tokens": 4096
  }
}
```



#### 3.2 Python 执行逻辑
Python 端的 LangGraph 节点完全无感底层模型差异，直接使用标准 SDK 初始化：

```java
from langchain_openai import ChatOpenAI

def get_llm(config):
    return ChatOpenAI(
        model=config["model_name"],
        openai_api_key=config["api_key"],
        openai_api_base=config["base_url"], # 关键：指向 OneAPI
        temperature=config["temperature"]
    )
```

### 54 高级特性支持
#### 5.1 高可用与负载均衡
利用 OneAPI 的能力实现模型服务的高可用，RuoYi 无需开发相关逻辑：

+ **多渠道轮询**：在 OneAPI 后台配置 3 个 DeepSeek 的 API Key（可能有不同的账号配额）。
+ **自动降级**：当渠道 A 报错（如 429 Too Many Requests）时，OneAPI 自动重试渠道 B。
+ **加权路由**：根据不同渠道的响应速度或配额剩余量设置权重。

#### 4.2 计费闭环
虽然 OneAPI 也有计费日志，但**商业化结算以 RuoYi 为准**。

1. **消耗统计**：Python 引擎在推理结束时，从 LLM 响应中提取 `usage` 字段（包含 `prompt_tokens` 和 `completion_tokens`）。
2. **数据回传**：通过 SSE 的 `done` 事件回传给 RuoYi。
3. **算费扣除**：
    - RuoYi 监听到 `done` 事件。
    - 读取 `sys_ai_model` 中的单价 (`price_input`, `price_output`)。
    - 计算公式：`Cost = (prompt_tokens / 1000 * price_input) + (completion_tokens / 1000 * price_output)`。
    - 从用户钱包余额中扣除。

